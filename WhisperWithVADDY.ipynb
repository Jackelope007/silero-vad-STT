{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jackelope007/silero-vad-STT/blob/master/WhisperWithVADDY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Whisper with Silero VAD\n",
        "This notebook combines Whisper with a separate VAD. This improves long-form\n",
        "transcriptions, at the cost of possibly missing a few lines.\n",
        "\n",
        "**Changelog**\n",
        "*   2022-12-11: Added source separation to remove background music\n",
        "*   2022-11-29: Additional filtering\n",
        "*   2022-10-11: Lowered default VAD threshold\n",
        "*   2022-10-08: Improved DeepL translation quality\n",
        "*   2022-09-29: Added filtering for hallucinations (\"Thank you for watching!\", etc.)"
      ],
      "metadata": {
        "id": "qGS9GFEnOoB_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCqXqFgP2ri0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8b04c1-dffa-4b7e-fbe1-192d03abfa22"
      },
      "source": [
        "#@markdown **GPU check** (you typically want a V100, P100 or T4)\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-5bc4bf3d-a033-1238-4ed0-8e930b8d39d5)\n",
            "Tue Jul  4 13:40:26 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9TI-Q6m3qlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8372d67-86c9-4dbc-b4ab-55397a851e0e"
      },
      "source": [
        "#@markdown **Mount Google Drive** (skip this if your audio file isn't stored there)\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teF-Ut8Z7Gjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a9ccb5-41fc-4ae1-977b-a8e66e5d8ad4"
      },
      "source": [
        "#@markdown **Setup Whisper**\n",
        "!apt-get install sox libsox-fmt-mp3 libsndfile1 ffmpeg\n",
        "!pip install deepl srt ffmpeg-python spleeter\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "print(\"Done\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "The following additional packages will be installed:\n",
            "  libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3\n",
            "Suggested packages:\n",
            "  libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox-fmt-mp3 libsox3 sox\n",
            "0 upgraded, 9 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 623 kB of archives.\n",
            "After this operation, 1,950 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [225 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [10.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [31.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2build0.20.04.1 [102 kB]\n",
            "Fetched 623 kB in 0s (1,620 kB/s)\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "(Reading database ... 123069 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../1-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../2-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../3-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../4-libsox3_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-base_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../7-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../8-sox_14.4.2+git20190427-2+deb11u2build0.20.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Setting up sox (14.4.2+git20190427-2+deb11u2build0.20.04.1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Collecting deepl\n",
            "  Downloading deepl-1.15.0-py3-none-any.whl (32 kB)\n",
            "Collecting srt\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting spleeter\n",
            "  Downloading spleeter-2.3.2-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from deepl) (2.27.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Collecting httpx[http2]<0.20.0,>=0.19.0 (from spleeter)\n",
            "  Downloading httpx-0.19.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting librosa<0.9.0,>=0.8.0 (from spleeter)\n",
            "  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.8/203.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.39.0,>=0.38.0 (from spleeter)\n",
            "  Downloading llvmlite-0.38.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting norbert==0.2.1 (from spleeter)\n",
            "  Downloading norbert-0.2.1-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.2 in /usr/local/lib/python3.10/dist-packages (from spleeter) (1.22.4)\n",
            "Requirement already satisfied: pandas<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from spleeter) (1.5.3)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.19.4 in /usr/local/lib/python3.10/dist-packages (from spleeter) (3.20.3)\n",
            "Requirement already satisfied: tensorflow<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from spleeter) (2.12.0)\n",
            "Collecting typer<0.4.0,>=0.3.2 (from spleeter)\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from norbert==0.2.1->spleeter) (1.10.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.0.12)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.3.0)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3 (from httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.14.0,>=0.13.3 (from httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
            "  Downloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2<5,>=3 (from httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.2.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa<0.9.0,>=0.8.0->spleeter)\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.2->spleeter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.2->spleeter) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->deepl) (3.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (0.32.0)\n",
            "Collecting click<7.2.0,>=7.1.1 (from typer<0.4.0,>=0.3.2->spleeter)\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<3.0.0,>=2.5.0->spleeter) (0.40.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting h11<0.13,>=0.11 (from httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.7.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.1.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<3.0.0,>=2.5.0->spleeter) (0.2.0)\n",
            "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting numba>=0.43.0 (from librosa<0.9.0,>=0.8.0->spleeter)\n",
            "  Downloading numba-0.57.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading numba-0.57.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading numba-0.56.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading numba-0.56.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading numba-0.56.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading numba-0.55.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa<0.9.0,>=0.8.0->spleeter) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.9.0,>=0.8.0->spleeter) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa<0.9.0,>=0.8.0->spleeter) (1.15.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (2.3.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.9.0,>=0.8.0->spleeter) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3.0.0,>=2.5.0->spleeter) (3.2.2)\n",
            "Building wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=b0e3750c9a8852481558c8fbc099b9757da27d7763545916d5fd7254a2827b75\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "Successfully built srt\n",
            "Installing collected packages: rfc3986, srt, llvmlite, hyperframe, hpack, h11, ffmpeg-python, click, typer, numba, norbert, httpcore, h2, deepl, resampy, httpx, librosa, spleeter\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.3\n",
            "    Uninstalling click-8.1.3:\n",
            "      Successfully uninstalled click-8.1.3\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.7.0\n",
            "    Uninstalling typer-0.7.0:\n",
            "      Successfully uninstalled typer-0.7.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.0.post2\n",
            "    Uninstalling librosa-0.10.0.post2:\n",
            "      Successfully uninstalled librosa-0.10.0.post2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fiona 1.9.4.post1 requires click~=8.0, but you have click 7.1.2 which is incompatible.\n",
            "flask 2.2.5 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
            "pip-tools 6.13.0 requires click>=8, but you have click 7.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-7.1.2 deepl-1.15.0 ffmpeg-python-0.2.0 h11-0.12.0 h2-4.1.0 hpack-4.0.0 httpcore-0.13.7 httpx-0.19.0 hyperframe-6.0.1 librosa-0.8.1 llvmlite-0.38.1 norbert-0.2.1 numba-0.55.2 resampy-0.4.2 rfc3986-1.5.0 spleeter-2.3.2 srt-3.5.3 typer-0.3.2\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-bd7pgc7z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-bd7pgc7z\n",
            "  Resolved https://github.com/openai/whisper.git to commit f572f2161ba831bae131364c3bffdead7af6d210\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.55.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230314)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.6)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (0.38.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798232 sha256=a3ed02d8583bf4f956b8651e35659dfd53e91dce535b393bde2dc2a270deabec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yfdhno5q/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230314 tiktoken-0.3.3\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Upload audio file to Colab** <br>\n",
        "#@markdown If this step fails, or is very slow, try one of these options:\n",
        "#@markdown * Drag your file into the Files sidebar, and set audio_path to the filename\n",
        "#@markdown * OR upload it to Google Drive, mount it, and set audio_path to the absolute path\n",
        "#@markdown * OR upload it to a service like Litterbox, and set audio_path to the URL\n",
        "from google.colab import files\n",
        "files = files.upload()\n",
        "if len(files) > 0:\n",
        "    uploaded_file = list(files)[0]\n",
        "    print(\"Upload complete\")\n"
      ],
      "metadata": {
        "id": "jh24lirNZnXT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "6bd14c94-96f5-4128-b029-fe131d86ad4a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ab631991-23b5-4e7c-b576-d7cdcf3b3da3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ab631991-23b5-4e7c-b576-d7cdcf3b3da3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Test audio.m4a to Test audio (1).m4a\n",
            "Upload complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QffxtNsJeYw",
        "outputId": "9f0e1419-cf76-4b2c-d209-ebca5ab447b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sos9vsxPkIN7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "9a70928e-1d6e-4d26-8897-527d6bb1ad3d"
      },
      "source": [
        "#@markdown **Run Whisper**\n",
        "\n",
        "# @markdown Required settings:\n",
        "audio_path = \"Test Audio.m4a\"  # @param {type:\"string\"}\n",
        "model_size = \"medium\"  # @param [\"medium\", \"large\"]\n",
        "language = \"english\"  # @param {type:\"string\"}\n",
        "translation_mode = \"Whisper -> DeepL\"  # @param [\"End-to-end Whisper (default)\", \"Whisper -> DeepL\", \"No translation\"]\n",
        "# @markdown Advanced settings:\n",
        "deepl_authkey = \"\"  # @param {type:\"string\"}\n",
        "source_separation = False  # @param {type:\"boolean\"}\n",
        "vad_threshold = 0.4  # @param {type:\"number\"}\n",
        "chunk_threshold = 3.0  # @param {type:\"number\"}\n",
        "deepl_target_lang = \"EN-US\"  # @param {type:\"string\"}\n",
        "max_attempts = 1  # @param {type:\"integer\"}\n",
        "initial_prompt = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import whisper\n",
        "import os\n",
        "import ffmpeg\n",
        "import srt\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "import deepl\n",
        "import urllib.request\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "# Configuration\n",
        "assert max_attempts >= 1\n",
        "assert vad_threshold >= 0.01\n",
        "assert chunk_threshold >= 0.1\n",
        "assert audio_path != \"\"\n",
        "assert language != \"\"\n",
        "if translation_mode == \"End-to-end Whisper (default)\":\n",
        "    task = \"translate\"\n",
        "    run_deepl = False\n",
        "elif translation_mode == \"Whisper -> DeepL\":\n",
        "    task = \"transcribe\"\n",
        "    run_deepl = True\n",
        "elif translation_mode == \"No translation\":\n",
        "    task = \"transcribe\"\n",
        "    run_deepl = False\n",
        "else:\n",
        "    raise ValueError(\"Invalid translation mode\")\n",
        "if initial_prompt.strip() == \"\":\n",
        "    initial_prompt = None\n",
        "\n",
        "if \"http://\" in audio_path or \"https://\" in audio_path:\n",
        "    print(\"Downloading audio...\")\n",
        "    urllib.request.urlretrieve(audio_path, \"input_file\")\n",
        "    audio_path = \"input_file\"\n",
        "else:\n",
        "    if not os.path.exists(audio_path):\n",
        "        try:\n",
        "            audio_path = uploaded_file\n",
        "            if not os.path.exists(audio_path):\n",
        "                raise ValueError(\"Input audio not found. Is your audio_path correct?\")\n",
        "        except NameError:\n",
        "            raise ValueError(\"Input audio not found. Did you upload a file?\")\n",
        "\n",
        "out_path = os.path.splitext(audio_path)[0] + \".srt\"\n",
        "out_path_pre = os.path.splitext(audio_path)[0] + \"_Untranslated.srt\"\n",
        "if source_separation:\n",
        "    print(\"Separating vocals...\")\n",
        "    !ffprobe -i \"{audio_path}\" -show_entries format=duration -v quiet -of csv=\"p=0\" > input_length\n",
        "    with open(\"input_length\") as f:\n",
        "        input_length = int(float(f.read())) + 1\n",
        "    !spleeter separate -d {input_length} -p spleeter:2stems -o output \"{audio_path}\"\n",
        "    spleeter_dir = os.path.basename(os.path.splitext(audio_path)[0])\n",
        "    audio_path = \"output/\" + spleeter_dir + \"/vocals.wav\"\n",
        "\n",
        "print(\"Encoding audio...\")\n",
        "if not os.path.exists(\"vad_chunks\"):\n",
        "    os.mkdir(\"vad_chunks\")\n",
        "ffmpeg.input(audio_path).output(\n",
        "    \"vad_chunks/silero_temp.wav\",\n",
        "    ar=\"16000\",\n",
        "    ac=\"1\",\n",
        "    acodec=\"pcm_s16le\",\n",
        "    map_metadata=\"-1\",\n",
        "    fflags=\"+bitexact\",\n",
        ").overwrite_output().run(quiet=True)\n",
        "\n",
        "print(\"Running VAD...\")\n",
        "model, utils = torch.hub.load(\n",
        "    repo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\", onnx=False\n",
        ")\n",
        "\n",
        "(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
        "\n",
        "# Generate VAD timestamps\n",
        "VAD_SR = 16000\n",
        "wav = read_audio(\"vad_chunks/silero_temp.wav\", sampling_rate=VAD_SR)\n",
        "t = get_speech_timestamps(wav, model, sampling_rate=VAD_SR, threshold=vad_threshold)\n",
        "\n",
        "# Add a bit of padding, and remove small gaps\n",
        "for i in range(len(t)):\n",
        "    t[i][\"start\"] = max(0, t[i][\"start\"] - 3200)  # 0.2s head\n",
        "    t[i][\"end\"] = min(wav.shape[0] - 16, t[i][\"end\"] + 20800)  # 1.3s tail\n",
        "    if i > 0 and t[i][\"start\"] < t[i - 1][\"end\"]:\n",
        "        t[i][\"start\"] = t[i - 1][\"end\"]  # Remove overlap\n",
        "\n",
        "# If breaks are longer than chunk_threshold seconds, split into a new audio file\n",
        "# This'll effectively turn long transcriptions into many shorter ones\n",
        "u = [[]]\n",
        "for i in range(len(t)):\n",
        "    if i > 0 and t[i][\"start\"] > t[i - 1][\"end\"] + (chunk_threshold * VAD_SR):\n",
        "        u.append([])\n",
        "    u[-1].append(t[i])\n",
        "\n",
        "# Merge speech chunks\n",
        "for i in range(len(u)):\n",
        "    save_audio(\n",
        "        \"vad_chunks/\" + str(i) + \".wav\",\n",
        "        collect_chunks(u[i], wav),\n",
        "        sampling_rate=VAD_SR,\n",
        "    )\n",
        "os.remove(\"vad_chunks/silero_temp.wav\")\n",
        "\n",
        "# Convert timestamps to seconds\n",
        "for i in range(len(u)):\n",
        "    time = 0.0\n",
        "    offset = 0.0\n",
        "    for j in range(len(u[i])):\n",
        "        u[i][j][\"start\"] /= VAD_SR\n",
        "        u[i][j][\"end\"] /= VAD_SR\n",
        "        u[i][j][\"chunk_start\"] = time\n",
        "        time += u[i][j][\"end\"] - u[i][j][\"start\"]\n",
        "        u[i][j][\"chunk_end\"] = time\n",
        "        if j == 0:\n",
        "            offset += u[i][j][\"start\"]\n",
        "        else:\n",
        "            offset += u[i][j][\"start\"] - u[i][j - 1][\"end\"]\n",
        "        u[i][j][\"offset\"] = offset\n",
        "\n",
        "# Run Whisper on each audio chunk\n",
        "print(\"Running Whisper...\")\n",
        "model = whisper.load_model(model_size)\n",
        "subs = []\n",
        "segment_info = []\n",
        "sub_index = 1\n",
        "suppress_low = [\n",
        "    \"Thank you\",\n",
        "    \"Thanks for\",\n",
        "    \"ike and \",\n",
        "    \"Bye.\",\n",
        "    \"Bye!\",\n",
        "    \"Bye bye!\",\n",
        "    \"lease sub\",\n",
        "    \"The end.\",\n",
        "    \"視聴\",\n",
        "]\n",
        "suppress_high = [\n",
        "    \"ubscribe\",\n",
        "    \"my channel\",\n",
        "    \"the channel\",\n",
        "    \"our channel\",\n",
        "    \"ollow me on\",\n",
        "    \"for watching\",\n",
        "    \"hank you for watching\",\n",
        "    \"for your viewing\",\n",
        "    \"r viewing\",\n",
        "    \"Amara\",\n",
        "    \"next video\",\n",
        "    \"full video\",\n",
        "    \"ranslation by\",\n",
        "    \"ranslated by\",\n",
        "    \"ee you next week\",\n",
        "    \"ご視聴\",\n",
        "    \"視聴ありがとうございました\",\n",
        "]\n",
        "for i in tqdm(range(len(u))):\n",
        "    line_buffer = []  # Used for DeepL\n",
        "    for x in range(max_attempts):\n",
        "        result = model.transcribe(\n",
        "            \"vad_chunks/\" + str(i) + \".wav\", task=task, language=language, initial_prompt=initial_prompt\n",
        "        )\n",
        "        # Break if result doesn't end with severe hallucinations\n",
        "        if len(result[\"segments\"]) == 0:\n",
        "            break\n",
        "        elif result[\"segments\"][-1][\"end\"] < u[i][-1][\"chunk_end\"] + 10.0:\n",
        "            break\n",
        "        elif x+1 < max_attempts:\n",
        "            print(\"Retrying chunk\", i)\n",
        "    for r in result[\"segments\"]:\n",
        "        # Skip audio timestamped after the chunk has ended\n",
        "        if r[\"start\"] > u[i][-1][\"chunk_end\"]:\n",
        "            continue\n",
        "        # Reduce log probability for certain words/phrases\n",
        "        for s in suppress_low:\n",
        "            if s in r[\"text\"]:\n",
        "                r[\"avg_logprob\"] -= 0.15\n",
        "        for s in suppress_high:\n",
        "            if s in r[\"text\"]:\n",
        "                r[\"avg_logprob\"] -= 0.35\n",
        "        # Keep segment info for debugging\n",
        "        del r[\"tokens\"]\n",
        "        segment_info.append(r)\n",
        "        # Skip if log prob is low or no speech prob is high\n",
        "        if r[\"avg_logprob\"] < -1.0 or r[\"no_speech_prob\"] > 0.7:\n",
        "            continue\n",
        "        # Set start timestamp\n",
        "        start = r[\"start\"] + u[i][0][\"offset\"]\n",
        "        for j in range(len(u[i])):\n",
        "            if (\n",
        "                r[\"start\"] >= u[i][j][\"chunk_start\"]\n",
        "                and r[\"start\"] <= u[i][j][\"chunk_end\"]\n",
        "            ):\n",
        "                start = r[\"start\"] + u[i][j][\"offset\"]\n",
        "                break\n",
        "        # Prevent overlapping subs\n",
        "        if len(subs) > 0:\n",
        "            last_end = datetime.timedelta.total_seconds(subs[-1].end)\n",
        "            if last_end > start:\n",
        "                subs[-1].end = datetime.timedelta(seconds=start)\n",
        "        # Set end timestamp\n",
        "        end = u[i][-1][\"end\"] + 0.5\n",
        "        for j in range(len(u[i])):\n",
        "            if r[\"end\"] >= u[i][j][\"chunk_start\"] and r[\"end\"] <= u[i][j][\"chunk_end\"]:\n",
        "                end = r[\"end\"] + u[i][j][\"offset\"]\n",
        "                break\n",
        "        # Add to SRT list\n",
        "        subs.append(\n",
        "            srt.Subtitle(\n",
        "                index=sub_index,\n",
        "                start=datetime.timedelta(seconds=start),\n",
        "                end=datetime.timedelta(seconds=end),\n",
        "                content=r[\"text\"].strip(),\n",
        "            )\n",
        "        )\n",
        "        sub_index += 1\n",
        "\n",
        "with open(\"segment_info.json\", \"w\", encoding=\"utf8\") as f:\n",
        "    json.dump(segment_info, f, indent=4)\n",
        "\n",
        "# DeepL translation\n",
        "translate_error = False\n",
        "if run_deepl:\n",
        "    print(\"Translating...\")\n",
        "    with open(out_path_pre, \"w\", encoding=\"utf8\") as f:\n",
        "        f.write(srt.compose(subs))\n",
        "    print(\"(Untranslated subs saved to\", out_path_pre, \")\")\n",
        "\n",
        "    lines = []\n",
        "    punct_match = [\"。\", \"、\", \",\", \".\", \"〜\", \"！\", \"!\", \"？\", \"?\", \"-\"]\n",
        "    for i in range(len(subs)):\n",
        "        if language.lower() == \"japanese\":\n",
        "            if subs[i].content[-1] not in punct_match:\n",
        "                subs[i].content += \"。\"\n",
        "            subs[i].content = \"「\" + subs[i].content + \"」\"\n",
        "        else:\n",
        "            if subs[i].content[-1] not in punct_match:\n",
        "                subs[i].content += \".\"\n",
        "            subs[i].content = '\"' + subs[i].content + '\"'\n",
        "    for i in range(len(subs)):\n",
        "        lines.append(subs[i].content)\n",
        "\n",
        "    grouped_lines = []\n",
        "    english_lines = []\n",
        "    for i, l in enumerate(lines):\n",
        "        if i % 30 == 0:\n",
        "            # Split lines into smaller groups, to prevent error 413\n",
        "            grouped_lines.append([])\n",
        "            if i != 0:\n",
        "                # Include previous 3 lines, to preserve context between splits\n",
        "                grouped_lines[-1].extend(grouped_lines[-2][-3:])\n",
        "        grouped_lines[-1].append(l.strip())\n",
        "\n",
        "    try:\n",
        "        translator = deepl.Translator(deepl_authkey)\n",
        "        for i, n in enumerate(tqdm(grouped_lines)):\n",
        "            x = [\"\\n\".join(n).strip()]\n",
        "            if language.lower() == \"japanese\":\n",
        "                result = translator.translate_text(x, source_lang=\"JA\", target_lang=deepl_target_lang)\n",
        "            else:\n",
        "                result = translator.translate_text(x, target_lang=deepl_target_lang)\n",
        "            english_tl = result[0].text.strip().splitlines()\n",
        "            assert len(english_tl) == len(n), (\n",
        "                \"Invalid translation line count (\"\n",
        "                + str(len(english_tl))\n",
        "                + \" vs \"\n",
        "                + str(len(n))\n",
        "                + \")\"\n",
        "            )\n",
        "            if i != 0:\n",
        "                english_tl = english_tl[3:]\n",
        "            remove_quotes = dict.fromkeys(map(ord, '\"„“‟”＂「」'), None)\n",
        "            for e in english_tl:\n",
        "                english_lines.append(\n",
        "                    e.strip().translate(remove_quotes).replace(\"’\", \"'\")\n",
        "                )\n",
        "        for i, e in enumerate(english_lines):\n",
        "            subs[i].content = e\n",
        "    except Exception as e:\n",
        "        print(\"DeepL translation error:\", e)\n",
        "        print(\"(downloading untranslated version instead)\")\n",
        "        translate_error = True\n",
        "\n",
        "# Write SRT file\n",
        "if translate_error:\n",
        "    files.download(out_path_pre)\n",
        "else:\n",
        "    # Removal of garbage lines\n",
        "    garbage_list = [\n",
        "        \"a\",\n",
        "        \"aa\",\n",
        "        \"ah\",\n",
        "        \"ahh\",\n",
        "        \"ha\",\n",
        "        \"haa\",\n",
        "        \"hah\",\n",
        "        \"haha\",\n",
        "        \"hahaha\",\n",
        "        \"mmm\",\n",
        "        \"mm\",\n",
        "        \"m\",\n",
        "        \"h\",\n",
        "        \"o\",\n",
        "        \"mh\",\n",
        "        \"mmh\",\n",
        "        \"hm\",\n",
        "        \"hmm\",\n",
        "        \"huh\",\n",
        "        \"oh\",\n",
        "    ]\n",
        "    need_context_lines = [\n",
        "        \"feelsgod\",\n",
        "        \"godbye\",\n",
        "        \"godnight\",\n",
        "        \"thankyou\",\n",
        "    ]\n",
        "    clean_subs = list()\n",
        "    last_line_garbage = False\n",
        "    for i in range(len(subs)):\n",
        "        c = subs[i].content\n",
        "        c = (\n",
        "            c.replace(\".\", \"\")\n",
        "            .replace(\",\", \"\")\n",
        "            .replace(\":\", \"\")\n",
        "            .replace(\";\", \"\")\n",
        "            .replace(\"!\", \"\")\n",
        "            .replace(\"?\", \"\")\n",
        "            .replace(\"-\", \" \")\n",
        "            .replace(\"  \", \" \")\n",
        "            .replace(\"  \", \" \")\n",
        "            .replace(\"  \", \" \")\n",
        "            .lower()\n",
        "            .replace(\"that feels\", \"feels\")\n",
        "            .replace(\"it feels\", \"feels\")\n",
        "            .replace(\"feels good\", \"feelsgood\")\n",
        "            .replace(\"good bye\", \"goodbye\")\n",
        "            .replace(\"good night\", \"goodnight\")\n",
        "            .replace(\"thank you\", \"thankyou\")\n",
        "            .replace(\"aaaaaa\", \"a\")\n",
        "            .replace(\"aaaa\", \"a\")\n",
        "            .replace(\"aa\", \"a\")\n",
        "            .replace(\"aa\", \"a\")\n",
        "            .replace(\"mmmmmm\", \"m\")\n",
        "            .replace(\"mmmm\", \"m\")\n",
        "            .replace(\"mm\", \"m\")\n",
        "            .replace(\"mm\", \"m\")\n",
        "            .replace(\"hhhhhh\", \"h\")\n",
        "            .replace(\"hhhh\", \"h\")\n",
        "            .replace(\"hh\", \"h\")\n",
        "            .replace(\"hh\", \"h\")\n",
        "            .replace(\"oooooo\", \"o\")\n",
        "            .replace(\"oooo\", \"o\")\n",
        "            .replace(\"oo\", \"o\")\n",
        "            .replace(\"oo\", \"o\")\n",
        "        )\n",
        "        is_garbage = True\n",
        "        for w in c.split(\" \"):\n",
        "            if w.strip() == \"\":\n",
        "                continue\n",
        "            if w.strip() in garbage_list:\n",
        "                continue\n",
        "            elif w.strip() in need_context_lines and last_line_garbage:\n",
        "                continue\n",
        "            else:\n",
        "                is_garbage = False\n",
        "                break\n",
        "        if not is_garbage:\n",
        "            clean_subs.append(subs[i])\n",
        "        last_line_garbage = is_garbage\n",
        "    with open(out_path, \"w\", encoding=\"utf8\") as f:\n",
        "        f.write(srt.compose(clean_subs))\n",
        "    print(\"\\nDone! Subs written to\", out_path)\n",
        "    print(\"Downloading SRT file:\")\n",
        "    files.download(out_path)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding audio...\n",
            "Running VAD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501: UserWarning: operator() profile_node %669 : int[] = prim::profile_ivalue(%667)\n",
            " does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Whisper...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:14<00:00, 108MiB/s]\n",
            "100%|██████████| 1/1 [00:12<00:00, 12.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done! Subs written to Test audio.srt\n",
            "Downloading SRT file:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dac54eb3-deb1-40e0-b9fb-4b328e7f6587\", \"Test audio.srt\", 1044)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}